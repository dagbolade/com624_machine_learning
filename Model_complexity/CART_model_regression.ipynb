{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Using decision tree technique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   origin                   car_name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "Empty DataFrame\n",
      "Columns: [mpg, cylinders, displacement, horsepower, weight, acceleration, model_year, origin, car_name]\n",
      "Index: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model_year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car_name      398 non-null    object \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 28.1+ KB\n",
      "\n",
      " None\n",
      "\n",
      " These are the instances with missing values after to conversion to float \n",
      "       mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "32   25.0          4          98.0         NaN    2046          19.0   \n",
      "126  21.0          6         200.0         NaN    2875          17.0   \n",
      "330  40.9          4          85.0         NaN    1835          17.3   \n",
      "336  23.6          4         140.0         NaN    2905          14.3   \n",
      "354  34.5          4         100.0         NaN    2320          15.8   \n",
      "374  23.0          4         151.0         NaN    3035          20.5   \n",
      "\n",
      "     model_year  origin              car_name  \n",
      "32           71       1            ford pinto  \n",
      "126          74       1         ford maverick  \n",
      "330          80       2  renault lecar deluxe  \n",
      "336          80       1    ford mustang cobra  \n",
      "354          81       2           renault 18i  \n",
      "374          82       1        amc concord dl  \n",
      "\n",
      "  dimension of train data  (278, 7)\n",
      "\n",
      "  dimension of test data  (120, 7)\n",
      "[19.59857143 29.03958333 14.40338983 29.03958333 19.59857143 14.40338983\n",
      " 33.50727273 33.50727273 19.59857143 14.40338983 29.03958333 19.59857143\n",
      " 19.59857143 29.03958333 33.50727273 23.9673913  14.40338983 19.59857143\n",
      " 14.40338983 33.50727273 23.9673913  29.03958333 19.59857143 23.9673913\n",
      " 29.03958333 33.50727273 29.03958333 33.50727273 14.40338983 29.03958333\n",
      " 19.59857143 14.40338983 23.9673913  29.03958333 29.03958333 14.40338983\n",
      " 23.9673913  14.40338983 29.03958333 23.9673913  23.9673913  29.03958333\n",
      " 19.59857143 29.03958333 19.59857143 19.59857143 19.59857143 14.40338983\n",
      " 23.9673913  19.59857143 23.9673913  29.03958333 14.40338983 14.40338983\n",
      " 29.03958333 23.9673913  14.40338983 14.40338983 33.50727273 33.50727273\n",
      " 29.03958333 33.50727273 14.40338983 19.59857143 14.40338983 29.03958333\n",
      " 19.59857143 19.59857143 29.03958333 14.40338983 19.59857143 23.9673913\n",
      " 14.40338983 29.03958333 14.40338983 23.9673913  33.50727273 14.40338983\n",
      " 14.40338983 23.9673913  19.59857143 14.40338983 33.50727273 23.9673913\n",
      " 33.50727273 19.59857143 19.59857143 19.59857143 33.50727273 29.03958333\n",
      " 14.40338983 19.59857143 19.59857143 33.50727273 33.50727273 19.59857143\n",
      " 33.50727273 33.50727273 23.9673913  19.59857143 19.59857143 14.40338983\n",
      " 14.40338983 33.50727273 19.59857143 19.59857143 33.50727273 23.9673913\n",
      " 19.59857143 19.59857143 19.59857143 29.03958333 29.03958333 19.59857143\n",
      " 23.9673913  33.50727273 14.40338983 23.9673913  29.03958333 33.50727273]\n",
      "mae:  2.92\n",
      "mse:  14.64\n",
      "Root mean square error:  3.83\n",
      "R2 score:  0.7496852364984337\n",
      "This is the prediction  [19.59857143] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#declaring header names\n",
    "autompg_headers = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "\n",
    "#read the data using the read_csv class\n",
    "mpg_data = read_csv('venv/auto_mpg_data.csv', names=autompg_headers)\n",
    "\n",
    "print(mpg_data.head(5))\n",
    "\n",
    "#check for any missing data\n",
    "miss_data = mpg_data[mpg_data.isna().any(axis=1)]\n",
    "print(miss_data)\n",
    "\n",
    "#check the data information\n",
    "print('\\n', mpg_data.info())\n",
    "\n",
    "#since the horsepower has an object data type, we convert it to float\n",
    "mpg_data['horsepower'] = pd.to_numeric(mpg_data['horsepower'], errors='coerce')\n",
    "\n",
    "#now lets re check or dataframe for missing values\n",
    "recheck_missing_data = mpg_data[mpg_data.isna().any(axis=1)]\n",
    "print('\\n These are the instances with missing values after to conversion to float \\n', recheck_missing_data )\n",
    "\n",
    "#using the simpleimputer function to replace the missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent') #either replace it with most frequent, median, mean and observe\n",
    "imputer.fit(mpg_data)\n",
    "new_data = imputer.transform(mpg_data)\n",
    "\n",
    "#reassign the new dataframe\n",
    "mpg_data = pd.DataFrame(data=new_data, columns=autompg_headers)\n",
    "\n",
    "#seperate the data into X(train) anf y(test) groups - training and target sets\n",
    "train_headers = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "\n",
    "taret_header = ['mpg']\n",
    "\n",
    "X = mpg_data[train_headers]\n",
    "y = mpg_data[taret_header]\n",
    "\n",
    "#get the independent variables\n",
    "X = mpg_data.iloc[:, 1:8].values #drop the car name as due to high cardinality and not being strong predictive\n",
    "\n",
    "#get the mpg\n",
    "#had to remove the .values as i was getting an error \"'numpy.ndarray' object has no attribute 'columns'\" in feature importances\n",
    "y = mpg_data.iloc[:, 0].values\n",
    "\n",
    "#split the data into 70:30 train and test mode\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "#check the dimension of train and test data\n",
    "print('\\n  dimension of train data ', X_train.shape)\n",
    "print('\\n  dimension of test data ', X_test.shape)\n",
    "\n",
    "#initialise the decision tree model\n",
    "dt_model = DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=1)\n",
    "\n",
    "#fit the regreession model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "#predict the model on test data\n",
    "y_pred = dt_model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#predict the model on train data\n",
    "y_pred_train = dt_model.predict(X_train)\n",
    "\n",
    "\n",
    "#evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#printing the model evaluation values\n",
    "print('mae:  {:.2f}'.format(mae))\n",
    "print('mse:  {:.2f}'.format(mse))\n",
    "print('Root mean square error:  {:.2f}'.format(rmse))\n",
    "print('R2 score: ', r2)\n",
    "\n",
    "#we can check the prediction for specific values\n",
    "pred_my_value = dt_model.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "using another configuration method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.22248062 32.28493151 17.22248062 32.28493151 17.22248062 17.22248062\n",
      " 26.08552632 32.28493151 17.22248062 17.22248062 32.28493151 17.22248062\n",
      " 17.22248062 26.08552632 32.28493151 26.08552632 17.22248062 17.22248062\n",
      " 17.22248062 32.28493151 26.08552632 26.08552632 17.22248062 26.08552632\n",
      " 32.28493151 26.08552632 32.28493151 32.28493151 17.22248062 32.28493151\n",
      " 17.22248062 17.22248062 26.08552632 32.28493151 26.08552632 17.22248062\n",
      " 26.08552632 17.22248062 32.28493151 26.08552632 26.08552632 26.08552632\n",
      " 17.22248062 32.28493151 17.22248062 17.22248062 17.22248062 17.22248062\n",
      " 26.08552632 17.22248062 26.08552632 32.28493151 17.22248062 17.22248062\n",
      " 26.08552632 26.08552632 17.22248062 17.22248062 26.08552632 32.28493151\n",
      " 32.28493151 32.28493151 17.22248062 17.22248062 17.22248062 32.28493151\n",
      " 17.22248062 17.22248062 32.28493151 17.22248062 17.22248062 26.08552632\n",
      " 17.22248062 32.28493151 17.22248062 26.08552632 32.28493151 17.22248062\n",
      " 17.22248062 26.08552632 17.22248062 17.22248062 32.28493151 26.08552632\n",
      " 32.28493151 17.22248062 17.22248062 17.22248062 32.28493151 32.28493151\n",
      " 17.22248062 17.22248062 17.22248062 32.28493151 26.08552632 17.22248062\n",
      " 32.28493151 26.08552632 26.08552632 17.22248062 17.22248062 17.22248062\n",
      " 17.22248062 32.28493151 17.22248062 17.22248062 32.28493151 26.08552632\n",
      " 17.22248062 17.22248062 17.22248062 32.28493151 32.28493151 17.22248062\n",
      " 26.08552632 32.28493151 17.22248062 26.08552632 32.28493151 32.28493151]\n",
      "mae:  3.40\n",
      "mse:  18.77\n",
      "Root mean square error:  4.33\n",
      "R2 score:  0.6790324674390048\n",
      "R2 score Train data:  0.6513489869253635\n",
      "This is the prediction  [17.22248062] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#declare SEED variable and set to 1 for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "\n",
    "#initialise the decision tree model\n",
    "dt_model = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)\n",
    "\n",
    "#fit the regreession model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "#predict the model on test data\n",
    "y_pred = dt_model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#predict the model on train data\n",
    "y_pred_train = dt_model.predict(X_train)\n",
    "\n",
    "\n",
    "#evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#the r2 for the train dataset\n",
    "r2_train = r2_score(y_train,y_pred_train)\n",
    "\n",
    "#printing the model evaluation values\n",
    "print('mae:  {:.2f}'.format(mae))\n",
    "print('mse:  {:.2f}'.format(mse))\n",
    "print('Root mean square error:  {:.2f}'.format(rmse))\n",
    "print('R2 score: ', r2)\n",
    "print('R2 score Train data: ', r2_train)\n",
    "\n",
    "#we can check the prediction for specific values\n",
    "pred_my_value = dt_model.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    USING ENSEMBLE APPROACH TO CONFIRM STABILITY OD THE MODEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.7   27.216 16.95  22.976 20.278 14.834 29.048 38.216 16.372 12.67\n",
      " 30.828 17.352 18.964 24.612 37.014 20.852 14.06  20.48  12.46  38.88\n",
      " 23.42  30.422 21.128 26.56  26.326 27.468 32.52  39.388 17.21  29.028\n",
      " 24.358 13.8   20.572 23.386 24.726 14.17  26.274 12.8   33.228 24.158\n",
      " 26.53  24.048 17.768 34.246 24.392 19.872 17.402 14.38  27.08  17.542\n",
      " 26.5   24.526 15.53  13.63  29.382 24.09  12.98  14.53  31.76  36.33\n",
      " 35.098 36.468 15.272 25.894 16.316 35.068 25.446 24.46  31.106 14.04\n",
      " 16.72  23.776 15.504 27.874 14.8   26.53  29.84  15.176 14.71  23.666\n",
      " 18.36  15.896 37.09  24.804 38.996 17.364 16.14  20.298 37.81  32.438\n",
      " 16.88  20.046 18.708 26.932 29.07  19.462 38.88  27.058 22.478 25.52\n",
      " 18.798 12.72  14.32  40.722 14.754 19.266 35.404 22.584 28.274 15.186\n",
      " 16.36  32.744 33.528 16.872 23.914 33.518 13.14  23.182 23.306 37.162]\n",
      "mae:  1.92\n",
      "mse:  7.31\n",
      "Root mean square error:  2.70\n",
      "R2 score:  0.8749384097822802\n",
      "R2 score Train data:  0.9817855814888954\n",
      "This is the prediction  [20.7] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree bagging\n",
    "#importing the necessary packages\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "#initialise the decision tree model\n",
    "dt_model = DecisionTreeRegressor( random_state=1)\n",
    "\n",
    "#instantiate the bagging regressor\n",
    "bg = BaggingRegressor(base_estimator=dt_model, n_estimators=50, random_state=0)\n",
    "\n",
    "#fit bg into the training set\n",
    "bg.fit(X_train, y_train)\n",
    "\n",
    "#predict the model on test data\n",
    "y_pred = bg.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#predict the model on train data\n",
    "y_pred_train = bg.predict(X_train)\n",
    "\n",
    "\n",
    "#evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#the r2 for the train dataset\n",
    "r2_train = r2_score(y_train,y_pred_train)\n",
    "\n",
    "#printing the model evaluation values\n",
    "print('mae:  {:.2f}'.format(mae))\n",
    "print('mse:  {:.2f}'.format(mse))\n",
    "print('Root mean square error:  {:.2f}'.format(rmse))\n",
    "print('R2 score: ', r2)\n",
    "print('R2 score Train data: ', r2_train)\n",
    "\n",
    "#we can check the prediction for specific values\n",
    "pred_my_value = bg.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "USING RANDOMM FOREST TECHNIQUE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.592 27.764 17.34  21.96  21.52  15.04  27.804 36.604 16.588 12.76\n",
      " 32.48  16.508 18.964 23.464 36.384 21.436 14.12  20.58  12.56  39.184\n",
      " 23.548 29.988 22.184 26.76  27.588 27.364 33.072 39.636 16.88  27.836\n",
      " 24.452 14.08  20.964 24.04  24.6   13.86  26.012 12.64  32.792 24.032\n",
      " 26.312 23.448 18.396 34.464 24.332 20.348 17.54  14.02  26.98  17.756\n",
      " 26.76  25.484 15.46  13.34  29.488 24.052 13.08  14.34  30.86  36.104\n",
      " 35.172 36.132 15.708 25.808 16.032 34.624 26.964 23.86  32.692 14.22\n",
      " 17.212 24.34  16.128 28.368 14.52  26.476 29.9   16.108 14.78  24.04\n",
      " 17.768 16.836 39.28  25.    39.308 17.752 16.612 20.34  36.548 31.988\n",
      " 16.744 20.016 17.588 26.496 29.14  19.724 40.124 27.176 22.368 25.844\n",
      " 18.2   12.68  14.16  40.792 15.508 19.664 35.06  21.46  28.012 16.108\n",
      " 16.9   32.704 30.832 16.992 23.9   33.08  13.2   22.988 22.532 37.672]\n",
      "mae:  2.01\n",
      "mse:  7.40\n",
      "Root mean square error:  2.72\n",
      "R2 score:  0.8734011952338309\n",
      "R2 score Train data:  0.979378827781849\n",
      "This is the prediction  [20.592] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree bagging\n",
    "#importing the necessary packages\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#initialise random forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=25, random_state=2)\n",
    "\n",
    "#fit rf into the training set\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#predict the model on test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#predict the model on train data\n",
    "y_pred_train = rf_model.predict(X_train)\n",
    "\n",
    "\n",
    "#evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#the r2 for the train dataset\n",
    "r2_train = r2_score(y_train,y_pred_train)\n",
    "\n",
    "#printing the model evaluation values\n",
    "print('mae:  {:.2f}'.format(mae))\n",
    "print('mse:  {:.2f}'.format(mse))\n",
    "print('Root mean square error:  {:.2f}'.format(rmse))\n",
    "print('R2 score: ', r2)\n",
    "print('R2 score Train data: ', r2_train)\n",
    "\n",
    "#we can check the prediction for specific values\n",
    "pred_my_value = rf_model.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RANDOM FOREST FOR FEATURES IMPORTANCE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise feature importance\n",
    "#create a pd.series of feature importance\n",
    "\n",
    "importances = pd.Series(data=rf_model.feature_importances_, index=X_train.columns)\n",
    "\n",
    "#sort base don prediction importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "#draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='blue')\n",
    "plt.title('Feature importances')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "USING ADABOOSTING TECHNIQUES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.80347222 29.11395349 19.01826923 25.45352113 22.53030303 18.13157895\n",
      " 28.97058824 39.89861111 17.72777778 16.328      30.09216867 18.54025974\n",
      " 19.24347826 26.67653061 39.49883721 20.85918367 16.328      18.1516129\n",
      " 16.328      39.3372549  22.84615385 29.20483092 24.57352941 24.57352941\n",
      " 28.25       28.97058824 31.76590909 39.74027778 16.75873016 28.74186047\n",
      " 28.8512987  16.328      20.4375     27.6530303  26.35714286 16.36792453\n",
      " 27.04714286 16.328      30.12394366 26.2875     26.12093023 26.35714286\n",
      " 20.84193548 30.81578947 27.40285714 19.68765432 18.81176471 16.328\n",
      " 26.36585366 18.08507463 24.57352941 28.18461538 17.62403846 16.36792453\n",
      " 29.06929134 23.22222222 16.27142857 16.328      29.60493827 38.925\n",
      " 35.88333333 38.925      18.1516129  28.35159236 20.72222222 30.39893617\n",
      " 28.18227848 29.06929134 29.93806452 16.36792453 20.72222222 25.45352113\n",
      " 16.69324324 28.21287879 16.328      26.35714286 33.37578947 18.13157895\n",
      " 16.71568627 22.77083333 21.03655914 17.80185185 38.32307692 25.45352113\n",
      " 39.28470588 18.6        18.48571429 21.0972973  39.49883721 29.11153846\n",
      " 20.72222222 19.78313253 17.98918919 27.44285714 29.60493827 19.76704545\n",
      " 38.36635514 27.04714286 22.77083333 28.86050955 18.09516129 16.27142857\n",
      " 16.43015873 39.49883721 16.43015873 19.20107527 33.67191011 21.31684211\n",
      " 29.11395349 17.72777778 18.02375    28.59166667 28.98992248 17.72285714\n",
      " 22.84615385 34.38287671 16.27142857 21.08053691 25.45352113 35.29782609]\n",
      "mae:  2.78\n",
      "mse:  12.78\n",
      "Root mean square error:  3.57\n",
      "R2 score:  0.781491234792845\n",
      "R2 score Train data:  0.8475410387248777\n",
      "This is the prediction  [19.80347222] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ADAPTIVE BOOSTING\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "\n",
    "#initialise the decision tree model\n",
    "dt_model = DecisionTreeRegressor(max_depth=2, random_state=1)\n",
    "\n",
    "#instantiate the Adaboosting regressor\n",
    "ada = AdaBoostRegressor(base_estimator=dt_model, n_estimators=180, random_state=1)\n",
    "\n",
    "#fit ada into the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "#predict the model on test data\n",
    "y_pred = ada.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#predict the model on train data\n",
    "y_pred_train = ada.predict(X_train)\n",
    "\n",
    "\n",
    "#evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#the r2 for the train dataset\n",
    "r2_train = r2_score(y_train,y_pred_train)\n",
    "\n",
    "#printing the model evaluation values\n",
    "print('mae:  {:.2f}'.format(mae))\n",
    "print('mse:  {:.2f}'.format(mse))\n",
    "print('Root mean square error:  {:.2f}'.format(rmse))\n",
    "print('R2 score: ', r2)\n",
    "print('R2 score Train data: ', r2_train)\n",
    "\n",
    "#we can check the prediction for specific values\n",
    "pred_my_value = ada.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gradient Boosting Ensembling technique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.17776545 26.6350864  16.8954886  21.658619   20.91991605 15.30164494\n",
      " 29.50296737 35.48514852 16.64707959 12.58601678 29.92640571 18.22381567\n",
      " 18.18947351 24.94434249 37.23981126 21.68936309 13.95433874 20.40085224\n",
      " 12.69217425 38.11902032 24.10150019 30.69258257 21.93478093 27.15601196\n",
      " 24.46484733 26.664731   32.02172148 38.21797142 17.39413887 30.59462427\n",
      " 24.61636918 14.06530838 19.16652256 25.55741009 25.03173512 13.68504681\n",
      " 26.58935983 12.68177541 39.31929601 24.32355445 26.65384767 22.26204551\n",
      " 19.16435028 34.05103547 25.34487482 19.28361816 17.92031609 13.83697396\n",
      " 27.16422771 17.60446542 27.15601196 25.47642899 15.38530564 13.05573407\n",
      " 29.48690616 23.75157998 13.59583849 14.05974086 30.98192821 33.49299015\n",
      " 31.07294446 32.80391215 16.48690617 26.95773688 16.77016243 36.47481699\n",
      " 31.62229533 24.02063793 30.26179149 13.49722106 17.96520905 24.29472329\n",
      " 15.32604454 28.19746998 14.79077451 27.41252588 28.89744758 16.56406959\n",
      " 15.04754397 23.17948251 18.10750153 17.92838487 37.49503277 24.05384065\n",
      " 36.42123653 17.66410076 16.16185083 20.43548739 38.26593801 31.8561062\n",
      " 16.63872828 19.8013878  17.85089763 26.60428296 29.34423034 18.12754204\n",
      " 38.50831328 25.60435458 21.98662019 23.05261592 18.43510537 11.77586464\n",
      " 13.87226674 36.61464142 15.03126092 19.36798276 35.19501145 21.26566187\n",
      " 24.96429998 16.21891332 17.16651863 32.28268747 29.84401751 16.74795762\n",
      " 23.72515996 33.64123233 13.99596625 24.05704322 23.93890827 34.73410419]\n",
      "mae:  1.98\n",
      "mse:  7.25\n",
      "Root mean square error:  2.69\n",
      "R2 score:  0.8759629826914233\n",
      "R2 score Train data:  0.9897075789168949\n",
      "This is the prediction  [21.17776545] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ADAPTIVE BOOSTING\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "#initialise the decision tree model\n",
    "dt_model = DecisionTreeRegressor(max_depth=2, random_state=1)\n",
    "\n",
    "#instantiate the Adaboosting regressor\n",
    "grd = GradientBoostingRegressor(n_estimators=200, random_state=1, max_depth=4)\n",
    "\n",
    "#fit ada into the training set\n",
    "grd.fit(X_train, y_train)\n",
    "\n",
    "#predict the model on test data\n",
    "y_pred = grd.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#predict the model on train data\n",
    "y_pred_train = grd.predict(X_train)\n",
    "\n",
    "\n",
    "#evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#the r2 for the train dataset\n",
    "r2_train = r2_score(y_train,y_pred_train)\n",
    "\n",
    "#printing the model evaluation values\n",
    "print('mae:  {:.2f}'.format(mae))\n",
    "print('mse:  {:.2f}'.format(mse))\n",
    "print('Root mean square error:  {:.2f}'.format(rmse))\n",
    "print('R2 score: ', r2)\n",
    "print('R2 score Train data: ', r2_train)\n",
    "\n",
    "#we can check the prediction for specific values\n",
    "pred_my_value = grd.predict([[6, 171.0, 97.0, 2984, 14.5, 75, 1]])\n",
    "print(\"This is the prediction \", pred_my_value, '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
